
# Some AI LLM models have been known to follow the instructions of this prompt.
# OpRt_.meta-llama/llama-3.1-405b-instruct
# Llama-augment

# Some AI LLM model outputs may be too narrowly focused for the purposes of this prompt.
# OpRt_.deepseek/deepseek-r1-distill-llama-70b

# Llama 3.1 models and Llama Distill/Reasoning models are suggested.

# Some OpenWebUI Web Search parameters may have been tested.
#
# Search Result Count 18
# Concurrent Requests 20

# ATTRIBUTION-AI: et. al.



### Task:
Analyze the chat history to determine if search queries are needed.

Specifically generate separate relevant queries to retrieve official documentation (eg. official API documentation from the project's website), relevant source code (eg. relevant source files from the project's GitHub repository), official issue trackers (eg. GitHub Issues for the project, project website bugzilla subdomain), technical community sites (eg. Stack Overflow, Reddit), and separately, general information sources (eg. relevant Wikipedia articles).

Generate multiple specific queries for each information source category (aim for at least 3-5 per category).
Use specific terminology, error messages, and version numbers when applicable.
Combine keywords with search operators for more targeted results.
Focus queries explicitly on finding workarounds and bugfixes.
Always err on the side of generating more queries rather than fewer.

- Respond **EXCLUSIVELY** with a JSON object. Any form of extra commentary, explanation, or additional text is strictly prohibited.
- When generating search queries, respond in the format: { "queries": ["query1", "query2"] }, ensuring each query is distinct, concise, and relevant to the topic.
- Be concise and focused on composing high-quality search queries, avoiding unnecessary elaboration, commentary, or assumptions.

- At least 12-15 distinct search queries.

- If and only if it is entirely certain that no useful results can be retrieved by a search, return: { "queries": [] }.
- Err on the side of suggesting search queries if there is **any chance** they might provide useful or updated information.
- Today's date is: {{CURRENT_DATE}}.


### Output:
Strictly return in JSON format:
{
  "queries": ["query1", "query2"]
}

### Chat History:
<chat_history>
{{MESSAGES:END:6}}
</chat_history>








_ Condensed _

# ATTRIBUTION-AI: et. al. (partial)
#Please rewrite this prompt to better work within the limitations of smaller Large Language Models, as low as 8b parameters with little or no code review training.



Analyze the chat history to determine if search queries are needed. Create specific queries to retrieve from each of:
official documentation (project websites, API docs),
relevant source code files (GitHub repository files),
issue trackers (eg. GitHub Issues for the project, project website bugzilla subdomain),
technical community sites (eg. Stack Overflow, Reddit),
command references (official website API/ABI docs),
function call references (official website API/ABI docs),
general information (Wikipedia, tutorials).

Generate multiple specific queries for each information source category (aim for at least 2-5 per category).
Include specific terminology, error messages, and version numbers as applicable.
Use search operators (site:, filetype:sh, filetype:c, filetype:cpp, filetype:md, filetype:txt) when helpful.
Focus queries explicitly on finding workarounds, bugfixes, solutions, explanations, syntax, command reference pages, and function call reference pages.
Always err on the side of generating more queries rather than fewer.

- Respond **EXCLUSIVELY** with a JSON object. Any form of extra commentary, explanation, or additional text is strictly prohibited.
- When generating search queries, respond in the format: { "queries": ["query1", "query2"] }, ensuring each query is distinct, concise, and relevant to the topic.
- Be concise and focused on composing high-quality search queries, avoiding unnecessary elaboration, commentary, or assumptions.

- At least 12-15 distinct search queries.

- Err on the side of suggesting search queries if there is **any chance** they might provide useful or updated information.


### Output:
Strictly return in JSON format:
{
  "queries": ["query1", "query2"]
}

### Chat History:
<chat_history>
{{MESSAGES:END:6}}
</chat_history>










_ EXAMPLE _
EXAMPLE orig (from  https://github.com/open-webui/open-webui/blob/main/backend/open_webui/config.py  'DEFAULT_QUERY_GENERATION_PROMPT_TEMPLATE')

### Task:
Analyze the chat history to determine the necessity of generating search queries, in the given language. By default, **prioritize generating 1-3 broad and relevant search queries** unless it is absolutely certain that no additional information is required. The aim is to retrieve comprehensive, updated, and valuable information even with minimal uncertainty. If no search is unequivocally needed, return an empty list.

### Guidelines:
- Respond **EXCLUSIVELY** with a JSON object. Any form of extra commentary, explanation, or additional text is strictly prohibited.
- When generating search queries, respond in the format: { "queries": ["query1", "query2"] }, ensuring each query is distinct, concise, and relevant to the topic.
- If and only if it is entirely certain that no useful results can be retrieved by a search, return: { "queries": [] }.
- Err on the side of suggesting search queries if there is **any chance** they might provide useful or updated information.
- Be concise and focused on composing high-quality search queries, avoiding unnecessary elaboration, commentary, or assumptions.
- Today's date is: {{CURRENT_DATE}}.
- Always prioritize providing actionable and broad queries that maximize informational coverage.

### Output:
Strictly return in JSON format:
{
  "queries": ["query1", "query2"]
}

### Chat History:
<chat_history>
{{MESSAGES:END:6}}
</chat_history>
